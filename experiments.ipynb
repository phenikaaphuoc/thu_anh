{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n",
      "720 1280\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def put_text(image, text, y, color=(0, 0, 255)):\n",
    "    cv2.putText(image, text, (10, 50 + y), cv2.FONT_HERSHEY_COMPLEX, 1, color, 2)\n",
    "    return image\n",
    "\n",
    "def draw_line(image, h):\n",
    "    _, width, _ = image.shape\n",
    "    color = (0, 255, 0)  # You can change this to set the line color (B, G, R)\n",
    "    thickness = 2  # You can change this to set the line thickness\n",
    "    start_point = (50, h)  # You can change this to set the starting point of the line\n",
    "    end_point = (width - 50, h)  # You can change this to set the ending point of the line\n",
    "    image = cv2.line(image, start_point, end_point, color, thickness)\n",
    "    return image\n",
    "\n",
    "file_path = r\"D:\\video2\\20240107_151948.bag\"\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "rs.config.enable_device_from_file(config, file_path, repeat_playback=False)\n",
    "pipeline.start(config)\n",
    "count = 0\n",
    "window_name = \"hihi\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, 800, 600) \n",
    "while True:\n",
    "    try:\n",
    "        # Get frameset of depth\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        count += 1\n",
    "        if not (count % 2):\n",
    "            continue\n",
    "\n",
    "        # Get color frame\n",
    "        color_frame = frames.get_color_frame()\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        frame = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        h_im, w_im, _ = frame.shape\n",
    "        results = pose.process(frame)\n",
    "        print(h_im,w_im)\n",
    "        if results.pose_landmarks:\n",
    "            left_y = results.pose_landmarks.landmark[15].y * h_im\n",
    "            right_y = results.pose_landmarks.landmark[16].y * h_im\n",
    "            centre = results.pose_landmarks.landmark[24].y * h_im - \\\n",
    "                     (results.pose_landmarks.landmark[24].y * h_im - results.pose_landmarks.landmark[12].y * h_im) * 0.2\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            is_action = False\n",
    "            if left_y <=centre or right_y<=centre:\n",
    "                is_action = True\n",
    "            frame = put_text(frame, f\"Left_y: {left_y:.2f}\", 100)\n",
    "            frame = put_text(frame, f\"Right_y: {right_y:.2f}\", 50)\n",
    "            frame = put_text(frame, f\"Center: {centre:.2f}\", 150)\n",
    "            frame = put_text(frame, f\"isaction: {is_action}\", 200)\n",
    "            frame = draw_line(frame,int(centre))\n",
    "            cv2.imshow(\"hihi\", frame)\n",
    "            if cv2.waitKey(1)==ord('q'):\n",
    "                break# Use cv2.waitKey(1) instead of cv2.waitKey(0) for non-blocking display\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "pipeline.stop()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\phuoc\\appdata\\local\\temp\\ipykernel_18332\\1453932197.py\u001b[0m(87)\u001b[0;36msegment_video\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from pathlib import Path\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import glob\n",
    "import pyrealsense2 as rs\n",
    "from tqdm import tqdm\n",
    "class Action:\n",
    "    def __init__(self, opt_path):\n",
    "        self.opt = read_yaml(opt_path)\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.posedetector = self.mp_pose.Pose()\n",
    "        self.count = 0\n",
    "        self.is_action = None\n",
    "        self.num_num_sub_video = 0\n",
    "        self.w,self.h = self.opt['image'].values()\n",
    "\n",
    "    def new_start(self, file_path):\n",
    "        self.pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        rs.config.enable_device_from_file(config, file_path, repeat_playback=False)\n",
    "        self.pipeline.start(config)\n",
    "\n",
    "        self.count = 0\n",
    "        self.is_action = None\n",
    "        self.num_sub_video = 0\n",
    "        name_action = os.path.basename(os.path.dirname(file_path))\n",
    "        self.folder_output = os.path.join(self.opt['out_folder'], name_action)\n",
    "        os.makedirs(self.folder_output, exist_ok=True)\n",
    "        self.input_id = os.path.basename(file_path).split(\".\")[0]\n",
    "\n",
    "    def get_key_points(self, frame):\n",
    "        h_im, _, _ = frame.shape\n",
    "        results = self.posedetector.process(frame)\n",
    "        left_y, right_y, centre = None,None,None\n",
    "        if results.pose_landmarks:\n",
    "            left_y = results.pose_landmarks.landmark[15].y * h_im\n",
    "            right_y = results.pose_landmarks.landmark[16].y * h_im\n",
    "            centre = results.pose_landmarks.landmark[24].y * h_im - \\\n",
    "                    (results.pose_landmarks.landmark[24].y * h_im - results.pose_landmarks.landmark[12].y * h_im) * self.opt['rate_up']\n",
    "        return left_y, right_y, centre, results\n",
    "\n",
    "    def start_capture(self):\n",
    "        name = f\"{self.input_id}_sub_{self.num_sub_video}.mp4\"\n",
    "        output_file = os.path.join(self.folder_output, name)\n",
    "        self.num_sub_video += 1\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter(output_file, fourcc, self.opt['out_fps'], (self.w, self.h))\n",
    "        print(\"start caputure: \",output_file)\n",
    "\n",
    "    def check_action(self, left_y, right_y, centre):\n",
    "        return left_y < centre or right_y < centre\n",
    "\n",
    "    def update_action(self, is_action, frame):\n",
    "        if self.is_action:\n",
    "                self.out.write(frame)\n",
    "        if is_action:\n",
    "            self.count = max(1, self.count + 1)\n",
    "            if self.count >= self.opt['thresh_frame_action']:\n",
    "                if self.is_action is False or self.is_action is None:\n",
    "                    self.start_capture()\n",
    "                self.is_action = True\n",
    "        else:\n",
    "            self.count = min(-1, self.count - 1)\n",
    "            if self.count <= -self.opt['thresh_frame_no_action']:\n",
    "                if self.is_action:\n",
    "                    self.out.release()\n",
    "                    print(\"end action\")\n",
    "                self.is_action = False\n",
    "\n",
    "    def add_new_frame(self, frame):\n",
    "        left_y, right_y, centre, results = self.get_key_points(frame)\n",
    "        frame = cv2.resize(frame,(self.w,self.h))\n",
    "        if left_y is not None:\n",
    "            is_action = self.check_action(left_y, right_y, centre)\n",
    "            self.update_action(is_action, frame)\n",
    "        else:\n",
    "            self.update_action(self.is_action, frame)\n",
    "            \n",
    "    def segment_video(self):\n",
    "        count = 0\n",
    "        while True:\n",
    "            # try:\n",
    "                import pdb;pdb.set_trace()\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                count += 1 \n",
    "                color_frame = frames.get_color_frame()\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                rgb_image = cv2.cvtColor(color_image,cv2.COLOR_BGR2RGB)\n",
    "                self.add_new_frame(rgb_image)\n",
    "            # except Exception as e:\n",
    "            #     print(e)\n",
    "            #     break\n",
    "        self.pipeline.release()\n",
    "    def segment_video_folder(self):\n",
    "        for sub_folder in tqdm(glob.glob(os.path.join(self.opt['input_folder'], \"*\")), desc='Processing Subfolders'):\n",
    "            for path in tqdm(glob.glob(os.path.join(sub_folder, \"*\")), desc=f'Processing Files in {os.path.basename(sub_folder)}', leave=False):\n",
    "                self.new_start(path)\n",
    "                self.segment_video()\n",
    "            \n",
    "                \n",
    "       \n",
    "            \n",
    "\n",
    "\n",
    "# Assuming you have a valid opt.yaml file and rs is the RealSense module\n",
    "# You should also have a loop to capture frames and call add_new_frame method\n",
    "# Example:\n",
    "action = Action(r\"D:\\thu_anh\\config.yaml\")\n",
    "action.segment_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "action.start_capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
